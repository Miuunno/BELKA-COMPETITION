{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install rdkit\n!pip install duckdb","metadata":{"execution":{"iopub.status.busy":"2024-06-22T03:25:43.795805Z","iopub.execute_input":"2024-06-22T03:25:43.796105Z","iopub.status.idle":"2024-06-22T03:26:14.863647Z","shell.execute_reply.started":"2024-06-22T03:25:43.796055Z","shell.execute_reply":"2024-06-22T03:26:14.862406Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting rdkit\n  Downloading rdkit-2023.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rdkit) (1.26.4)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from rdkit) (9.5.0)\nDownloading rdkit-2023.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.9/34.9 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: rdkit\nSuccessfully installed rdkit-2023.9.6\nCollecting duckdb\n  Downloading duckdb-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (762 bytes)\nDownloading duckdb-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.5/18.5 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: duckdb\nSuccessfully installed duckdb-1.0.0\n","output_type":"stream"}]},{"cell_type":"code","source":"from rdkit import Chem\nfrom rdkit.Chem import rdchem\nimport torch\nimport torchvision\nfrom torch import nn, Tensor\nfrom torchvision.transforms import v2\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nimport pandas as pd\nimport time\nimport torch.nn as nn\nfrom rdkit import Chem\nfrom rdkit.Chem import AllChem\nimport numpy as np\nimport torch.nn.functional as F\nimport re\nfrom torchvision.models.convnext import Permute\nimport time \nimport random\nimport duckdb","metadata":{"execution":{"iopub.status.busy":"2024-06-22T03:26:40.196567Z","iopub.execute_input":"2024-06-22T03:26:40.197512Z","iopub.status.idle":"2024-06-22T03:26:44.020958Z","shell.execute_reply.started":"2024-06-22T03:26:40.197474Z","shell.execute_reply":"2024-06-22T03:26:44.020199Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_path = '/kaggle/input/leash-BELKA/train.parquet'\ntest_path = '/kaggle/input/leash-BELKA/test.parquet'\n\ncon = duckdb.connect()\n\ndf = con.query(f\"\"\"(SELECT *\n                        FROM parquet_scan('{train_path}')\n                        WHERE binds = 0\n                        ORDER BY random()\n                        LIMIT 300000)\n                        UNION ALL\n                        (SELECT *\n                        FROM parquet_scan('{train_path}')\n                        WHERE binds = 1\n                        ORDER BY random()\n                        LIMIT 300000)\"\"\").df()\n\ncon.close()","metadata":{"execution":{"iopub.status.busy":"2024-06-22T03:26:44.022624Z","iopub.execute_input":"2024-06-22T03:26:44.023458Z","iopub.status.idle":"2024-06-22T03:26:44.159473Z","shell.execute_reply.started":"2024-06-22T03:26:44.023422Z","shell.execute_reply":"2024-06-22T03:26:44.158209Z"},"trusted":true},"execution_count":4,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIOException\u001b[0m                               Traceback (most recent call last)","Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m test_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/leash-BELKA/test.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m con \u001b[38;5;241m=\u001b[39m duckdb\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[0;32m----> 6\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mcon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[38;5;124;43m(SELECT *\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;43m                        FROM parquet_scan(\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtrain_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m)\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;43m                        WHERE binds = 0\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;43m                        ORDER BY random()\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;43m                        LIMIT 300000)\u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;43m                        UNION ALL\u001b[39;49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;43m                        (SELECT *\u001b[39;49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;43m                        FROM parquet_scan(\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtrain_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m)\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;43m                        WHERE binds = 1\u001b[39;49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;43m                        ORDER BY random()\u001b[39;49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;43m                        LIMIT 300000)\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdf()\n\u001b[1;32m     18\u001b[0m con\u001b[38;5;241m.\u001b[39mclose()\n","\u001b[0;31mIOException\u001b[0m: IO Error: No files found that match the pattern \"/kaggle/input/leash-BELKA/train.parquet\""],"ename":"IOException","evalue":"IO Error: No files found that match the pattern \"/kaggle/input/leash-BELKA/train.parquet\"","output_type":"error"}]},{"cell_type":"code","source":"Chiral = {\"CHI_UNSPECIFIED\":50,  \"CHI_TETRAHEDRAL_CW\":51, \"CHI_TETRAHEDRAL_CCW\":52, \"CHI_OTHER\":53}\nHybridization = {\"UNSPECIFIED\":54, \"S\":55, \"SP\":56, \"SP2\":57, \"SP3\":58, \"SP3D\":59, \"SP3D2\":60, \"OTHER\":61}\nenc_atom = {\"H\": 0, \"C\": 1, \"O\": 2, \"N\": 3, \"S\": 4, \"F\": 5, \"D\": 6, \"B\": 7, \"I\": 8, \"Dy\":9, \"Br\":10, \"Cl\":11, \"Si\":12}\nenc_num_hs = {0:13, 1: 14, 2: 15, 3: 16, 4:17, 5:18, 6:19, 7:20, 8:21}\nenc_total_degree = {0: 22, 1: 23, 2: 24, 3: 25, 4:26}\nenc_Is_In_ring = {0: 27, 1: 28}\nenc_Is_Aromatic = {0: 29, 1: 30}\nenc_formal_charge = {0:31, 1: 32, 2: 33, 3: 34, 4:35, 5:36, 6:37, 7:38, 8:39, -1:40}\nenc_get_total_valence = {0:41, 1: 42, 2:43, 3: 44, 4:45, 5:46, 6:47, 7:48, 8:49}\nenc_not_smile = {\"(\": 62, \")\" : 63, \"[\": 64, \"]\":65, \"=\":66, \"#\":67, \"/\":68, \"@\":69, \"1\": 70, \"2\": 71, \"3\":72, \"4\":73, \"5\": 74, \"6\": 75, \"7\":76, '8':77, \"9\": 78, \"+\":79, \"-\":80}\nH_Vector = 0\nlowerReg = re.compile(r'^[a-z]+$')\ndef islower(s):\n    return lowerReg.match(s) is not None\n\nupperReg = re.compile(r'^[A-Z]+$')\ndef isupper(s):\n    return upperReg.match(s) is not None\n\ndef calc_atom_feature(atom):\n    feature = [enc_atom[atom.GetSymbol()]]\n    feature.append(enc_num_hs[atom.GetTotalNumHs()])\n    feature.append(enc_total_degree[atom.GetTotalDegree()])\n    feature.append(enc_Is_In_ring[atom.IsInRing()*1])\n    feature.append(enc_Is_Aromatic[atom.GetIsAromatic()*1])\n    feature.append(enc_formal_charge[atom.GetFormalCharge()])\n    feature.append(enc_get_total_valence[atom.GetTotalValence()])\n    feature.append(Chiral[str(atom.GetChiralTag())])\n    feature.append(Hybridization[str(atom.GetHybridization())])\n    return(feature)\n\n\ndef calc_structure_feature(c):\n    return enc_not_smile[c]\n#     elif c== '+' :\n#         feature[8] = 1\n#         flag = 1\n#     elif c== '-' :\n#         feature[9] = 1\n#         flag = 1\n#     elif c.isdigit() == True:\n#         if flag == 0:\n#             if c in label:\n#                 feature[20] = 1\n#             else:\n#                 label.append(c)\n#                 feature[19] = 1\n#         else:\n#             feature[int(c)-1+12] = 1\n#             flag = 0\n#     return(feature,flag,label)\ndef calc_featurevector(mol, smiles):\n    molfeature=[]\n    idx = 0\n    for c in smiles:\n        if islower(c) == True: \n                if c == \"y\":\n                    molfeature.append(81)\n                if c == \"r\":\n                    molfeature.append(82)\n                if c == \"s\":\n                    molfeature.append(83)\n                if c == \"c\":\n                    molfeature.append(84)\n                if c == \"0\":\n                    molfeature.append(85)\n                if c == \"n\":\n                    molfeature.append(86)\n                if c == \"i\":\n                    molfeature.append(87)\n        elif isupper(c) == True:\n            if c == 'H':\n                molfeature.append(H_Vector)\n            else:\n                molfeature.extend(calc_atom_feature(rdchem.Mol.GetAtomWithIdx(mol, idx)))\n                idx = idx + 1         \n        else:   \n            f = calc_structure_feature(c)\n            molfeature.append(f)\n    return(molfeature)\n\ndef mol_to_feature(mol,n):\n    try: defaultSMILES = Chem.MolToSmiles(mol, kekuleSmiles=False, isomericSmiles=True, rootedAtAtom=int(n))\n    except: defaultSMILES = Chem.MolToSmiles(mol, kekuleSmiles=False, isomericSmiles=True)\n    try: isomerSMILES = Chem.MolToSmiles(mol, kekuleSmiles=True, isomericSmiles=True, rootedAtAtom=int(n))\n    except: isomerSMILES = Chem.MolToSmiles(mol, kekuleSmiles=True, isomericSmiles=True)\n    return calc_featurevector(Chem.MolFromSmiles(defaultSMILES), isomerSMILES)\n\ndef mol_to_allSMILESfeature(mol, atomsize):\n    idx, features =0,  []\n    while idx < mol.GetNumAtoms():\n        try: defaultSMILES = Chem.MolToSmiles(mol, kekuleSmiles=False, isomericSmiles=True, rootedAtAtom=int(idx))\n        except: break\n        isomerSMILES = Chem.MolToSmiles(mol, kekuleSmiles=True, isomericSmiles=True, rootedAtAtom=int(idx))\n        features.append(calc_featurevector(Chem.MolFromSmiles(defaultSMILES), isomerSMILES,atomsize))\n        idx = idx + 1\n    return features","metadata":{"execution":{"iopub.status.busy":"2024-06-21T16:52:01.190968Z","iopub.execute_input":"2024-06-21T16:52:01.191281Z","iopub.status.idle":"2024-06-21T16:52:01.217445Z","shell.execute_reply.started":"2024-06-21T16:52:01.191256Z","shell.execute_reply":"2024-06-21T16:52:01.216440Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Block(nn.Module):\n    def __init__(self, dim):\n        super().__init__()\n        self.block = nn.Sequential(\n                        nn.Conv1d(dim, dim, kernel_size=1, groups=dim),\n                        nn.BatchNorm1d(dim, eps=1e-06),\n                        Permute([0, 2, 1]),\n                        nn.Linear(dim, dim*4),\n                        nn.GELU(),\n                        nn.Linear(dim*4, dim), Permute([0, 2, 1]), \n            nn.Conv1d(dim, dim, kernel_size=1, groups=dim),\n                        nn.BatchNorm1d(dim, eps=1e-06),\n                        Permute([0, 2, 1]),\n                        nn.Linear(dim, dim*4),\n                        nn.GELU(),\n                        nn.Linear(dim*4, dim), Permute([0, 2, 1]), \n            nn.Conv1d(dim, dim, kernel_size=1, groups=dim),\n                        nn.BatchNorm1d(dim, eps=1e-06),\n                        Permute([0, 2, 1]),\n                        nn.Linear(dim, dim*4),\n                        nn.GELU(),\n                        nn.Linear(dim*4, dim), Permute([0, 2, 1]), \n            nn.Conv1d(dim, dim, kernel_size=1, groups=dim),\n                        nn.BatchNorm1d(dim, eps=1e-06),\n                        Permute([0, 2, 1]),\n                        nn.Linear(dim, dim*4),\n                        nn.GELU(),\n                        nn.Linear(dim*4, dim), Permute([0, 2, 1]))\n    def forward(self, x):\n        out = self.block(x)\n        out += x\n        return out\nclass MyModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        block = Block\n        layer = []\n        layer.append(nn.Sequential(nn.Conv1d(1, 2, kernel_size=351), nn.BatchNorm1d(2, eps=1e-06)))\n        dim=2\n        size = 350\n        for z in range(3):\n            if z != 2:\n                for i in range(3):\n                    layer.append(block(dim=dim))\n            else: \n                for i in range(12):\n                    layer.append(block(dim=dim))\n            size /= 2\n            layer.append(nn.Sequential(nn.BatchNorm1d(dim), nn.Conv1d(dim, dim*2, kernel_size=int(size)+ 1)))\n            dim *= 2\n        for i in range(3):\n            layer.append(block(dim=dim))\n        self.features = nn.Sequential(*layer)\n        self.classifier = nn.Sequential(nn.AdaptiveAvgPool1d(1), nn.BatchNorm1d(dim), nn.Flatten(1), nn.Linear(dim, 2))\n    def forward(self, x):\n        x = self.features(x)\n        x = self.classifier(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:12:33.773133Z","iopub.execute_input":"2024-06-21T17:12:33.773895Z","iopub.status.idle":"2024-06-21T17:12:33.792008Z","shell.execute_reply.started":"2024-06-21T17:12:33.773857Z","shell.execute_reply":"2024-06-21T17:12:33.791007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = MyModel()\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\nif torch.cuda.device_count() > 1:\n    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n    model = nn.DataParallel(model)\nmodel = model.to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.001)\ncriterion = torch.nn.BCEWithLogitsLoss()","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:12:35.262264Z","iopub.execute_input":"2024-06-21T17:12:35.262635Z","iopub.status.idle":"2024-06-21T17:12:35.357719Z","shell.execute_reply.started":"2024-06-21T17:12:35.262606Z","shell.execute_reply":"2024-06-21T17:12:35.356798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Mydataset(Dataset):\n    def __init__(self, mol_value, binds, names, transform):\n        self.mol_value = mol_value\n        self.binds = binds\n        self.transform = transform\n        self.names = names\n    def __len__(self):\n        return len(self.mol_value)\n    def __getitem__ (self, idx):\n        mol_value = self.mol_value[idx]\n        bind = self.binds[idx]\n        names = self.names[idx]\n        if bind == 1:\n            bind = torch.tensor([[0, 1]]).type(torch.float32)\n        else:\n            bind = torch.tensor([[1, 0]]).type(torch.float32)\n        mol_value = mol_to_feature(Chem.MolFromSmiles(mol_value), -1)\n        length = len(mol_value)\n        if names == \"BRD4\":\n            mol_value.append(88)\n        if names == \"HSA\":\n            mol_value.append(89)\n        if names == \"sEH\":\n            mol_value.append(90)\n        mol_value.extend([-1]*(700-length))\n        mol_value = [((i+1)/91) for i in mol_value]\n        if self.transform:\n            mol_value = torch.from_numpy(np.array(mol_value))\n            mol_value = self.transform(mol_value)\n        return mol_value, bind\nclass Mytest(Dataset):\n    def __init__(self, mol_value, names, transform):\n        self.mol_value = mol_value\n        self.transform = transform\n        self.names = names\n    def __len__(self):\n        return len(self.mol_value)\n    def __getitem__ (self, idx):\n        mol_value = self.mol_value[idx]\n        names = self.names[idx]\n        mol_value = mol_to_feature(Chem.MolFromSmiles(mol_value), -1)\n        length = len(mol_value)\n        mol_value = mol_to_feature(Chem.MolFromSmiles(mol_value), -1)\n        length = len(mol_value)\n        if names == \"BRD4\":\n            mol_value.append(88)\n        if names == \"HSA\":\n            mol_value.append(89)\n        if names == \"sEH\":\n            mol_value.append(90)\n        mol_value.extend([-1]*(700-length))\n        mol_value = [((i+1)/91) for i in mol_value]\n        if self.transform:\n            mol_value = torch.from_numpy(np.array(mol_value))\n            mol_value = self.transform(mol_value)\n        return mol_value","metadata":{"execution":{"iopub.status.busy":"2024-06-21T16:52:01.502013Z","iopub.execute_input":"2024-06-21T16:52:01.502311Z","iopub.status.idle":"2024-06-21T16:52:01.517326Z","shell.execute_reply.started":"2024-06-21T16:52:01.502286Z","shell.execute_reply":"2024-06-21T16:52:01.516159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.train()\ntrain_loader = DataLoader(Mydataset(df[\"molecule_smiles\"], df[\"binds\"], df[\"protein_name\"] ,transform=v2.Compose([v2.ToDtype(torch.float32)])), batch_size=1000, shuffle=True, pin_memory=\"cpu\")\nloss_1 = 0\nacc_1 = 0\nfor epoch in range(10):\n    print(\"prepare your data\")\n    time_train = time.time()\n    print(\"it is time to fed the model\")\n    for i, (a, b) in enumerate(train_loader):\n        a = a.unsqueeze(dim=1).to(device)\n        out = model(a)\n        del a\n        b = b.squeeze().to(device)\n        loss = criterion(out, b)\n        loss_1 += loss\n        loss.backward()\n        _, predictions = torch.max(out, 1)\n        del out, \n        _, target = torch.max(b, 1)\n        acc = torch.mean((predictions == target.to(device))*torch.tensor(1, dtype=torch.float32))\n        acc_1 += acc\n        if (i+10)%10 == 0 and i !=0:\n            print(\n            \"[{epoch}: {i}/{len}] \\n\"\n            \"Time_train: {time:.3f} \\n\"\n            \"Train_loss: {loss:.4f} \\n\"\n            \"Train_acc: {acc:.4f} \\n\"\n            \"Learning_rate: {rate:.4f} \\n\".format(epoch=epoch, i=i, len=len(train_loader), time=time.time()-time_train, loss=(loss_1/10).item(), acc=(acc_1/10).item(), rate=optimizer.param_groups[0][\"lr\"]))\n            time_train = time.time()\n            optimizer.step()\n            optimizer.zero_grad()\n            loss_1 = 0\n            acc_1 = 0\n        del predictions, b, acc, target, loss\n    torch.save({\"last_epoch\": epoch + 1,\"model_state\": model.state_dict(), \"optimizer\": optimizer.state_dict()}, \"/kaggle/working/checkpoint.pth.tar\")\n\nwith torch.no_grad():\n    model.eval()\n    df = pd.read_csv(\"/kaggle/input/leash-BELKA/test.csv\")\n    df1 = pd.DataFrame({\"id\", \"binds\"})\n    test_loader = DataLoader(Mytest(df[\"molecule_smiles\"], df[\"protein_name\"],transform=v2.Compose([v2.ToDtype(torch.float32)])), batch_size=10000, shuffle=True, pin_memory=\"cpu\")\n    pre_z = 0\n    for i , a in enumerate(test_loader):\n        out = model(a.squeeze().to(device))\n        _, out = torch.max(out, 1)\n        for z in range(10000):\n            df1.loc[pre_z] = {\"id\": df[\"id\"][pre_z], \"binds\": out[z].item()}\n            pre_z += 1\n        output = []\npd.DataFrame.to_csv(\"/kaggle/working/submission.csv\", df1)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:09:19.851008Z","iopub.execute_input":"2024-06-21T17:09:19.851645Z","iopub.status.idle":"2024-06-21T17:12:30.392708Z","shell.execute_reply.started":"2024-06-21T17:09:19.851612Z","shell.execute_reply":"2024-06-21T17:12:30.391121Z"},"trusted":true},"execution_count":null,"outputs":[]}]}